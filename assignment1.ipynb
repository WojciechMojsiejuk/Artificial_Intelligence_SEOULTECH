{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WojciechMojsiejuk/Artificial_Intelligence_SEOULTECH/blob/main/assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-ORnGHCPhM1"
      },
      "source": [
        "## Assignment #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbQVdrrapfG_"
      },
      "source": [
        "* Release date: 2022.09.27 Tue\n",
        "* Due date: **2022.10.04 Tue 23:59** (will not accept late submission)\n",
        "* Submission format: notebook file which can be executed in Colab environment\n",
        "* Weighting: 5% (total 50 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeVtMwumpcUu"
      },
      "source": [
        "1. **(10pts)** Calculate `rotation*x` and `x*rotation`. Explain how each computation is performed and why two results are the same.\n",
        "\n",
        "  ```python\n",
        "    import numpy as np\n",
        "\n",
        "    x = np.array([[2, 0]])\n",
        "    rotation = np.array([ [0, -1],\n",
        "                          [1,  0] ])\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    import numpy as np\n",
        "\n",
        "    x = np.array([[2, 0]])\n",
        "    rotation = np.array([ [0, -1],\n",
        "                          [1,  0] ])"
      ],
      "metadata": {
        "id": "GX7gyyjbarUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check what are the result of `x*rotation` and `rotation*x`"
      ],
      "metadata": {
        "id": "eoePqEV_etP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x*rotation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmlxFg43auUo",
        "outputId": "4a780c01-c5f1-4551-c6a0-753ffa1308fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [2, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rotation*x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sek1067ayvf",
        "outputId": "ed04559f-0b5b-4b45-eada-72f277ab9a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [2, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check dimmensionality of our tensors"
      ],
      "metadata": {
        "id": "H-y3ZL7Ie9wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7twzF9hcWJ-",
        "outputId": "4eca9ef3-7637-493d-de96-dc6731178ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rotation.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEiCDP28cYZy",
        "outputId": "33cc4a91-08b5-44ca-903a-b0c04c7a21d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer:\n",
        "\n",
        "Because of the broadcasting it is possible for us to compute the values in both conditions.\n",
        "\n",
        "## Proof:\n",
        "\n",
        "From the documentation of [numpy.multiply](https://numpy.org/doc/stable/reference/generated/numpy.multiply.html)\n",
        "```python\n",
        "numpy.multiply(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj]) = <ufunc 'multiply'>\n",
        "```\n",
        "Multiply arguments element-wise.\n",
        "\n",
        "Parameters\n",
        "x1, x2array_like\n",
        "Input arrays to be multiplied. If x1.shape != x2.shape, they must be **broadcastable** to a common shape (which becomes the shape of the output).\n",
        "\n",
        "## General Broadcasting Rules\n",
        "\n",
        "When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when\n",
        "\n",
        "- they are equal, or\n",
        "\n",
        "- one of them is 1\n",
        "\n",
        "[Source](https://numpy.org/doc/stable/user/basics.broadcasting.html)\n",
        "\n",
        "As we can see in our situation `x.shape` is `(1, 2)` which means it follows a second rule and therefore can be broadcasted (stretched) to match `rotation` dimensionality."
      ],
      "metadata": {
        "id": "BQoIqQxcbQSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_broadcasted = np.array([[2, 0],[2, 0]]) #we repeat the values of x to match the dimensionality of rotated matrix"
      ],
      "metadata": {
        "id": "FWG_2jr7fg5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_broadcasted.shape == rotation.shape # let's check if our broadcasted matrix is compatible with rotation matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vupbcqWXfspy",
        "outputId": "e469591c-024b-4738-942e-8622b508565b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us compute the values manually\n",
        "\n",
        "\\begin{equation}\n",
        "x^{\\text{broadcasted}} =\n",
        "\\begin{bmatrix}\n",
        "2 & 0\\\\\n",
        "2 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{rotation} =\n",
        "\\begin{bmatrix}\n",
        "0 & -1\\\\\n",
        "1 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jdopTxf_gJzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{equation}\n",
        "x^{\\text{broadcasted}}\\cdot\\text{rotation} =\n",
        "\\begin{bmatrix}\n",
        "2 & 0\\\\\n",
        "2 & 0\n",
        "\\end{bmatrix}\\cdot\n",
        "\\begin{bmatrix}\n",
        "0 & -1\\\\\n",
        "1 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "2\\cdot0 & 0\\cdot -1\\\\\n",
        "2\\cdot1 & 0\\cdot 0\n",
        "\\end{bmatrix}\n",
        "⇒\n",
        "\\begin{bmatrix}\n",
        "0 & 0\\\\\n",
        "2 & 0\n",
        "\\end{bmatrix}"
      ],
      "metadata": {
        "id": "nvUtS_9EhyuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_broadcasted*rotation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFm_IsGCgCMe",
        "outputId": "024760f8-dee6-4082-f17a-0aee6be464ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [2, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From Commutative Property of Multiplication we know that for an element-wise multiplication $a\\cdot b = b\\cdot a$, but nonetheless let's check other computation\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{rotation} \\cdot x^{\\text{broadcasted}}=\n",
        "\\begin{bmatrix}\n",
        "0 & -1\\\\\n",
        "1 & 0\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "2 & 0\\\\\n",
        "2 & 0\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "0\\cdot2 & -1\\cdot 0\\\\\n",
        "1\\cdot2 & 0\\cdot 0\n",
        "\\end{bmatrix}\n",
        "⇒\n",
        "\\begin{bmatrix}\n",
        "0 & 0\\\\\n",
        "2 & 0\n",
        "\\end{bmatrix}"
      ],
      "metadata": {
        "id": "SlAqOvbEiIU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotation*x_broadcasted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76xG6yXogFdK",
        "outputId": "bb3ae215-574b-4ced-e06e-518bf3ee8a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0],\n",
              "       [2, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARQKCA9sCpN-"
      },
      "source": [
        "2. **(5pts)** Suppose we have the following 2D tensor (i.e., a matrix). How to rearrange its values into 1D tensor (i.e., a vector) in a column major order?\n",
        "```python\n",
        "x = np.array([[1,  2,  3,  4],\n",
        "                 [5,  6,  7,  8],\n",
        "                 [9, 10, 11, 12]])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To flatten tensor to vector we can use [np.ravel](https://numpy.org/devdocs/reference/generated/numpy.ravel.html) method. To obtain a column major order we might specify a `order`parameter of a function and set it to `F` where `F` means to index the elements in column-major, Fortran-style order."
      ],
      "metadata": {
        "id": "_AQntLrBnjPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "x = np.array([[1,  2,  3,  4],\n",
        "              [5,  6,  7,  8],\n",
        "              [9, 10, 11, 12]])\n",
        "\n",
        "x_vector_cmo = np.ravel(x, order='F') \n",
        "\n",
        "pprint(x_vector_cmo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0W4b3gJaXjE",
        "outputId": "bddb5ab8-c9a9-4b4b-d2f3-f7c6c4e102b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([ 1,  5,  9,  2,  6, 10,  3,  7, 11,  4,  8, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0cUrs6OFJVn"
      },
      "source": [
        "3. **(5pts)** Compute a transpose of the matrix `x` in Problem 2 by using only `np.reshape` function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQuD49RIoDId",
        "outputId": "702176cc-41d5-47e2-8700-b8fb25290ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this task we could use our previously computed 1D vector and reshape it to swap axes $(3,4)⇒(4,3)$ "
      ],
      "metadata": {
        "id": "2mQU_fjwqvJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_t = np.reshape(x_vector_cmo,(4,3))"
      ],
      "metadata": {
        "id": "927pd3VVq8dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "or write np.ravel function as np.reshape where we specify the size of our matrix as (1, number of elements)\n"
      ],
      "metadata": {
        "id": "B666NH_5qq7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_t2 = np.reshape(np.reshape(x,(1,12),order='F'),(4,3))"
      ],
      "metadata": {
        "id": "UO6w32Ltom8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see both approaches give us the same result, which also matches the built-in functions for transposing matrix"
      ],
      "metadata": {
        "id": "5QoexDFirMMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(x_t)\n",
        "pprint(x_t2)\n",
        "print(x_t.shape)\n",
        "pprint(x.T) # built-in function for transposing \n",
        "pprint(np.transpose(x)) # built-in function for transposing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6qj0e3crTGV",
        "outputId": "9b58e379-423b-4555-bc77-ba19f980a506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([[ 1,  5,  9],\n",
            "       [ 2,  6, 10],\n",
            "       [ 3,  7, 11],\n",
            "       [ 4,  8, 12]])\n",
            "array([[ 1,  5,  9],\n",
            "       [ 2,  6, 10],\n",
            "       [ 3,  7, 11],\n",
            "       [ 4,  8, 12]])\n",
            "(4, 3)\n",
            "array([[ 1,  5,  9],\n",
            "       [ 2,  6, 10],\n",
            "       [ 3,  7, 11],\n",
            "       [ 4,  8, 12]])\n",
            "array([[ 1,  5,  9],\n",
            "       [ 2,  6, 10],\n",
            "       [ 3,  7, 11],\n",
            "       [ 4,  8, 12]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVzaCbniHnF6"
      },
      "source": [
        "4. **(5pts)** Perform vector arithmetic to create a `primes_squared_minus_one` vector, where the `i`th element is equal to the `i`th element in `primes` squared minus 1. For example, the second element of `primes_squared_minus_one` would be equal to `3^2 - 1 = 8`. Note that using `for` loop is not allowed.\n",
        "```python\n",
        "import numpy as np\n",
        "primes = np.array([2, 3, 5, 7, 11, 13])\n",
        "primes_squared_minus_one = ?\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "primes = np.array([2, 3, 5, 7, 11, 13])\n",
        "primes_squared_minus_one = primes**2-1\n",
        "pprint(primes_squared_minus_one)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auc6NMBxrjLM",
        "outputId": "991b466c-10b6-4821-d0bd-c1be3f4c8e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([  3,   8,  24,  48, 120, 168])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGIhrK8hVgjh"
      },
      "source": [
        "5. **(10pts)** Given any random matrices, compute the element-wise multiplication using a naive Python implementation and Numpy built-in function respectively. Compare the wall-clock times of these implementations as the size of matrices increases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_mul(x, y):\n",
        "  '''\n",
        "  naive_mul(x,y) \n",
        "  Returns the element-wise multiplication of two tensors of at most 2D.\n",
        "\n",
        "            Parameters:\n",
        "                    x (np.ndarray): first tensor of at most two dimensions\n",
        "                    y (np.ndarray): second tensor of at most two dimensions decimal integer\n",
        "\n",
        "            Returns:\n",
        "                    xy_mul (np.ndarray): element-wise multiplication of x and y\n",
        "  '''\n",
        "  try: \n",
        "    assert x.shape == y.shape\n",
        "  except AssertionError:\n",
        "      if len(x.shape) == 1:\n",
        "        if x.shape[0] == 1: \n",
        "          x=np.ones_like(y)*x\n",
        "        elif x.shape[0] == y.shape[1]:\n",
        "          temp = x.copy()\n",
        "          x = np.ones_like(y)\n",
        "          x[:,0]=temp\n",
        "          x[:,1]=temp\n",
        "        else:\n",
        "          raise ValueError(f'could not broadcast input array from shape {x.shape} into shape {y.shape}.')\n",
        "      elif len(y.shape) == 1:\n",
        "        if y.shape[0] == 1: \n",
        "          y=np.ones_like(x)*y\n",
        "        elif y.shape[0] == x.shape[1]:\n",
        "          temp = y.copy()\n",
        "          y = np.ones_like(x)\n",
        "          y[:,0]=temp\n",
        "          y[:,1]=temp\n",
        "        else:\n",
        "          raise ValueError(f'could not broadcast input array from shape {x.shape} into shape {y.shape}.')\n",
        "      else:\n",
        "        raise ValueError(f'could not broadcast input array from shape {x.shape} into shape {y.shape}.')\n",
        "  xy_mul = x.copy()\n",
        "  for i in range(xy_mul.shape[0]):\n",
        "    for j in range(xy_mul.shape[1]):\n",
        "      xy_mul[i, j] *= y[i, j]\n",
        "  return xy_mul"
      ],
      "metadata": {
        "id": "Wwad7yeTsIB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing solution for matrix * vector situations (not mandatory for this assignment, I just wanted to practise broadcasting)."
      ],
      "metadata": {
        "id": "pnqECUyM7Hbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.random.rand(2,2)\n",
        "y=np.random.rand(2)\n",
        "\n",
        "pprint(x)\n",
        "pprint(y)\n",
        "pprint(naive_mul(x,y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkvOhMSfscGg",
        "outputId": "0253847d-c692-4819-f819-2eda1bdaed26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array([[0.46490964, 0.22660092],\n",
            "       [0.45417363, 0.58932149]])\n",
            "array([0.93277473, 0.50754188])\n",
            "array([[0.43365596, 0.21136761],\n",
            "       [0.23051214, 0.29910534]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SIZE = [10**x for x in range(0, 4)]\n",
        "naive_time = []\n",
        "numpy_time = []\n",
        "\n",
        "for idx, size in enumerate(SIZE):\n",
        "  temp_naive_time = 0\n",
        "  temp_numpy_time = 0\n",
        "  for i in range(10): # Let's repeat the process few times and compute the mean to neglect the latency\n",
        "    x=np.random.rand(size, size)\n",
        "    y=np.random.rand(size, size)\n",
        "    \n",
        "    #naive implementation\n",
        "    start = time.time_ns() \n",
        "    naive_ans = naive_mul(x,y)\n",
        "    elapsed = time.time_ns()  - start\n",
        "    temp_naive_time += elapsed\n",
        "    \n",
        "    #numpy\n",
        "    start = time.time_ns() \n",
        "    numpy_ans = x*y\n",
        "    elapsed = time.time_ns()  - start\n",
        "    temp_numpy_time += elapsed\n",
        "\n",
        "    #verification\n",
        "    assert np.abs(naive_ans-numpy_ans).all() < 10**-3\n",
        "\n",
        "  naive_time.append(temp_naive_time/10)\n",
        "  numpy_time.append(temp_numpy_time/10)\n",
        "\n",
        "p_naive = np.poly1d(np.polyfit(SIZE, naive_time, 3))\n",
        "p_numpy = np.poly1d(np.polyfit(SIZE, numpy_time, 3))\n",
        "xp = np.logspace(0,3,100)\n",
        "\n",
        "plt.plot(SIZE, naive_time, 'bo', label='naive')\n",
        "plt.plot(xp,p_naive(xp), 'b:')\n",
        "plt.plot(SIZE, numpy_time, 'ro', label='numpy')\n",
        "plt.plot(xp,p_numpy(xp), 'r:')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('size of one axis of matrix')\n",
        "plt.ylabel('time (ns)')\n",
        "plt.legend()\n",
        "plt.title(\"Comparison of time elapsed for naive implementation and numpy element-wise multiplication\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "OnQ2KLpz7ZwK",
        "outputId": "69abed95-6d29-4aab-d78a-58658415bca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it can be seen naive implementation is usually 10-100 time slower than an optimized solution from numpy library. It can be observed that the difference between the solution is somewhat steady no matter the size of the matrices (except for really small matrices; $n<10$)"
      ],
      "metadata": {
        "id": "lwy7CtZzYFII"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDe6_vqqSe7f"
      },
      "source": [
        "6. **(15pts)** Consider MNIST classification problem covered during the class. For the details, please refer to the course material. In this example, we used the multilayer perceptron composed of an input layer with 512 hidden nodes and an output layer that produces predicted probabilities over 10 classes. In the class, we used GPU as a hardware accelerator to train our model.\n",
        "\n",
        "  Here, let's verify the actual benefit of using GPU for training. For this, compare the wall-clock times in the case of 1) using CPU and 2) using GPU to train MNIST classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images,test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Uy_xVW52ea1Y",
        "outputId": "6130a912-ee1b-4870-c2aa-74b34106498a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.48.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 55.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed gast-0.4.0 keras-2.10.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi #check if we use GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4VKvJk5fE-K",
        "outputId": "6ab8831b-e402-4ab3-c9bd-a5e0dd2b5d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "train_images = train_images.reshape((60000, 28*28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28*28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "start = time.time()\n",
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "elapsed = time.time() - start\n",
        "\n",
        "print('Elapsed time (CPU): %.4f' % elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL4dgQ5ffUSC",
        "outputId": "8cb04887-8e24-44a3-b5ac-69a9f619241d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.2571 - accuracy: 0.9277\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1039 - accuracy: 0.9686\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0685 - accuracy: 0.9800\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0498 - accuracy: 0.9849\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0372 - accuracy: 0.9889\n",
            "Elapsed time (CPU): 26.6657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now enable GPU"
      ],
      "metadata": {
        "id": "DoYyGKmdhZqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi #check if we use GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0K1fQsnhcXQ",
        "outputId": "dab4ed07-1f2d-409e-9635-0387399c4c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 27 10:37:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "train_images = train_images.reshape((60000, 28*28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28*28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "start = time.time()\n",
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "elapsed = time.time() - start\n",
        "\n",
        "print('Elapsed time (GPU): %.4f' % elapsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LceXZLQlhjj5",
        "outputId": "fd05baec-67b9-469f-8727-83588eb1c1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f87f02a1290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f87f02a1290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "469/469 [==============================] - 5s 3ms/step - loss: 0.2535 - accuracy: 0.9259\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1028 - accuracy: 0.9688\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0677 - accuracy: 0.9797\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.9854\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0370 - accuracy: 0.9886\n",
            "Elapsed time (GPU): 11.0071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Epoch 1/5\n",
        "469/469 [==============================] - 6s 12ms/step - loss: 0.2571 - accuracy: 0.9277\n",
        "Epoch 2/5\n",
        "469/469 [==============================] - 5s 11ms/step - loss: 0.1039 - accuracy: 0.9686\n",
        "Epoch 3/5\n",
        "469/469 [==============================] - 5s 11ms/step - loss: 0.0685 - accuracy: 0.9800\n",
        "Epoch 4/5\n",
        "469/469 [==============================] - 5s 11ms/step - loss: 0.0498 - accuracy: 0.9849\n",
        "Epoch 5/5\n",
        "469/469 [==============================] - 5s 11ms/step - loss: 0.0372 - accuracy: 0.9889\n",
        "Elapsed time (CPU): 26.6657\n",
        "```\n",
        "\n",
        "```\n",
        "Epoch 1/5\n",
        "469/469 [==============================] - 5s 3ms/step - loss: 0.2535 - accuracy: 0.9259\n",
        "Epoch 2/5\n",
        "469/469 [==============================] - 1s 3ms/step - loss: 0.1028 - accuracy: 0.9688\n",
        "Epoch 3/5\n",
        "469/469 [==============================] - 1s 3ms/step - loss: 0.0677 - accuracy: 0.9797\n",
        "Epoch 4/5\n",
        "469/469 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.9854\n",
        "Epoch 5/5\n",
        "469/469 [==============================] - 1s 3ms/step - loss: 0.0370 - accuracy: 0.9886\n",
        "Elapsed time (GPU): 11.0071\n",
        "```\n",
        "As we can see using GPU increased the speed of the training our model. Without GPU it took 26s to train model. With GPU it took only 11s."
      ],
      "metadata": {
        "id": "Yx6BgAoYieBm"
      }
    }
  ]
}